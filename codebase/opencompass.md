---
title: opencompass Usage Notes
date: 2025-08-25T00:00:00.000Z
tags:
  - eval
  - vllm
category: codebase
author: zyz
---
# opencompass Usage Notes

## ğŸ“– ç®€ä»‹

OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets.

## ğŸ“ å®˜æ–¹æ–‡æ¡£ä¸èµ„æº

[GitHub](https://github.com/open-compass/opencompass)
[Docs](https://opencompass.readthedocs.io/en/latest/)

## ğŸ“¦ å®‰è£…ä¸ç¯å¢ƒ

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
uv venv --python 3.10
uv init
uv add "opencompass[vllm]" langdetect "math-verify[antlr4_11_0]"
uv add "git+https://github.com/open-compass/human-eval.git#egg=human-eval"
```

## ğŸš€ åŸºç¡€ç”¨æ³•

### Config

#### è¿è¡Œ Config

```python
from mmengine.config import read_base
from opencompass.partitioners import NaivePartitioner
from opencompass.runners import LocalRunner
from opencompass.tasks import OpenICLInferTask

with read_base():
    from .datasets.IFEval.IFEval_gen import ifeval_datasets
    from .datasets.mmlu_pro.mmlu_pro_gen import mmlu_pro_datasets
    from .datasets.math.math_prm800k_500_gen import math_datasets
    from .datasets.humaneval.humaneval_gen import humaneval_datasets
    from .datasets.gpqa.gpqa_gen import gpqa_datasets
    from .datasets.aime2024.aime2024_gen import aime2024_datasets
    from .datasets.mbpp.mbpp_gen import mbpp_datasets
    from .models.ttls.qwen import models

datasets = [*mmlu_pro_datasets, *ifeval_datasets, *math_datasets, *humaneval_datasets, *gpqa_datasets, *aime2024_datasets, *mbpp_datasets]
models
```

æŒ‡å®šéœ€è¦è¯„æµ‹çš„æ¨¡å‹å’Œè¯„æµ‹é›†

```bash
VLLM_WORKER_MULTIPROC_METHOD=spawn \
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \
uv run nohup python3 run.py opencompass/configs/ttls.py --max-num-workers 8
```

ä»¥ä¸Šä¸º8å¡vllmè¯„æµ‹ç¤ºä¾‹ï¼Œç›¸åº”å¯ä»¥å‡å°‘å¡æ•°ï¼Œè°ƒæ•´`CUDA_VISIBLE_DEVICES` å’Œ `--max-num-workers` å³å¯

#### Model

```python
from opencompass.models import VLLMwithChatTemplate
from opencompass.utils.text_postprocessors import extract_non_reasoning_content

models = [
    dict(
        type=VLLMwithChatTemplate,
        abbr='qwen2.5-7b-instruct-vllm',
        path='',
        model_kwargs=dict(tensor_parallel_size=1),
        max_out_len=4096,
        batch_size=16,
        generation_kwargs=dict(temperature=0),
        run_cfg=dict(num_gpus=1),
    )
]
```

ä»¥ `Qwen2.5-7B-Instruct`ä¸ºä¾‹,åœ¨è¿è¡Œconfigä¸­åŠ è½½å¯¹åº”æ¨¡å‹ã€‚å¯¹äº`Qwen3`æ¶‰åŠThinkå¼€å…³çš„è¯·å‚è€ƒè¿›é˜¶ç”¨æ³•éƒ¨åˆ†ã€‚

#### Dataset

å½“å‰é€‰å–ä»¥ä¸‹æ•°æ®é›†ä½œä¸ºBenchmark

| Dataset   | Domain                | Desc                                                                |
| --------- | --------------------- | ------------------------------------------------------------------- |
| MMLU-Pro  | Knowledge             | é«˜éš¾åº¦å¤šå­¦ç§‘é€‰æ‹©é¢˜ï¼Œé€‰é¡¹æ›´å¤šï¼Œä¸“æµ‹å¤§æ¨¡å‹çŸ¥è¯†ä¸æ¨ç†èƒ½åŠ›ã€‚            |
| GPQA      | Knowledge             | ç ”ç©¶ç”Ÿæ°´å¹³ã€éš¾ä»¥æœç´¢çš„ç†ç§‘å¤šé€‰é¢˜ï¼Œè€ƒæŸ¥æ·±åº¦ç†è§£ä¸æ¨ç†ã€‚              |
| AIME 2024 | Math                  | 2024å¹´AIMEç«èµ›åŸé¢˜ï¼Œè¡¡é‡æ¨¡å‹é«˜ä¸­ç«èµ›æ•°å­¦è§£é¢˜èƒ½åŠ›ã€‚                  |
| Math 500  | Math                  | 500é“é«˜éš¾åº¦æ•°å­¦ç«èµ›é¢˜ï¼Œä¸»æµæ•°å­¦æ¨ç†è¯„æµ‹é›†ã€‚                         |
| Humaneval | Code                  | 164é“Pythonç¼–ç¨‹é¢˜ï¼Œä¸»æµä»£ç ç”Ÿæˆèƒ½åŠ›è¯„æµ‹é›†ã€‚                         |
| ~~MBPP~~  | ~~Code~~              | ~~974é“åŸºç¡€~~~~Python~~~~ç¼–ç¨‹é¢˜ï¼Œé€‚åˆåˆå­¦è€…ï¼Œå¸¸ç”¨äºä»£ç èƒ½åŠ›è¯„æµ‹ã€‚~~ |
| IFEval    | Instruction Following | ä¸»æµæŒ‡ä»¤è·Ÿéšèƒ½åŠ›è¯„æµ‹é›†ï¼Œè¦†ç›–å¤šä»»åŠ¡ã€‚                                |

> MBPPæµ‹è¯•ç²¾åº¦å·®å¼‚å¤§éš¾ä»¥å¯¹é½ï¼Œä¸é‡‡ç”¨

### Output

æ¨ç†ç»“æœé»˜è®¤å­˜å‚¨åœ¨`outputs/default`ä¸‹

#### Prediction

å¯ä»¥åœ¨ `outputs/default/<date>/predictions/<model abbr>`ä¸‹çœ‹åˆ°æ¨¡å‹å…·ä½“çš„ç”Ÿæˆå†…å®¹
å¯ä»¥æŸ¥çœ‹å…¶ä¸­`prediction`æ¥ç¡®è®¤æ¨¡å‹ç”Ÿæˆæ˜¯å¦å¼‚å¸¸

#### Summary

- Qwen2.5-7B-Instruct

  - 8å¡`vllm`è€—æ—¶ï¼š15min44s
    - è¯„æµ‹ç»“æœ
      ![image.png](https://raw.githubusercontent.com/kyriekevin/img_auto/main/Obsidian/202508251854378.png)
      ![image.png](https://raw.githubusercontent.com/kyriekevin/img_auto/main/Obsidian/202508251948585.png)
  - ç²¾åº¦å¯¹æ¯”

    | Datasets  | Opencompass | Official | Deviation  |
    | --------- | ----------- | -------- | ---------- |
    | MMLU-Pro  | 57.64       | 56.3     | +1.34      |
    | GPQA      | 34.34       | 36.4     | -2.06      |
    | HumanEval | 85.37       | 84.8     | +0.57      |
    | Math 500  | 76.2        | 75.5     | +0.7       |
    | ~~MBPP~~  | ~~58.99~~   | ~~79.2~~ | ~~-20.21~~ |
    | IFEval    | 71.72       | 71.2     | +0.52      |

    - vllmæœ¬èº«æ¨ç†æœ‰ç²¾åº¦æ³¢åŠ¨ï¼Œä¸”shotæ•°å¯èƒ½ä¸ä¸€è‡´ä¼šå¯¼è‡´ç²¾åº¦æ— æ³•å®Œå…¨å¯¹é½

## ğŸŒŸ è¿›é˜¶ç”¨æ³•

### Thinkå¼€å…³

```Python
from opencompass.models import VLLMwithChatTemplate
from opencompass.utils.text_postprocessors import extract_non_reasoning_content

models = [
    dict(
        type=VLLMwithChatTemplate,
        abbr='qwen3-8b-wo-think-vllm',
        path='',
        model_kwargs=dict(tensor_parallel_size=1),
        max_seq_len=32768,
        max_out_len=32000,
        batch_size=16,
        run_cfg=dict(num_gpus=1),
        chat_template_kwargs=dict(enable_thinking=False),
        generation_kwargs=dict(temperature=0.7, top_p=0.8, top_k=20),
        pred_postprocessor=dict(type=extract_non_reasoning_content)
    ),
    dict(
        type=VLLMwithChatTemplate,
        abbr='qwen3-8b-w-think-vllm',
        path='',
        model_kwargs=dict(tensor_parallel_size=1),
        max_seq_len=32768,
        max_out_len=32000,
        batch_size=16,
        run_cfg=dict(num_gpus=1),
        chat_template_kwargs=dict(enable_thinking=True),
        generation_kwargs=dict(temperature=0.6, top_p=0.95, top_k=20),
        pred_postprocessor=dict(type=extract_non_reasoning_content)
    ),
]
```

> æ³¨ï¼šé€šè¿‡`chat_template_kwargs`å­—æ®µæ§åˆ¶æ˜¯å¦å¼€å¯thinkï¼Œ`generation_kwargs`å‚è€ƒå®˜æ–¹`Best Practices`

- Qwen3 8B (Non-thinking)

  - 8å¡`vllm`è€—æ—¶ï¼š1h58min18s
  - è¯„æµ‹ç»“æœ
    ![image.png](https://raw.githubusercontent.com/kyriekevin/img_auto/main/Obsidian/202508252219885.png)
    ![image.png](https://raw.githubusercontent.com/kyriekevin/img_auto/main/Obsidian/202508252219273.png)
  - ç²¾åº¦å¯¹æ¯”

    | Datasets  | Opencompass | Official | Deviation |
    | --------- | ----------- | -------- | --------- |
    | GPQA      | 43.94       | 39.3     | +4.64     |
    | IFEval    | 82.81       | 83       | -0.19     |
    | Math 500  | 86.2        | 87.4     | -1.2      |
    | AIME 2024 | 26.67       | 29.1     | -2.43     |

- Qwen3 8B (thinking)

  - 8å¡`vllm`è€—æ—¶ï¼š3h19min26s
  - è¯„æµ‹ç»“æœ
    ![image.png](https://raw.githubusercontent.com/kyriekevin/img_auto/main/Obsidian/202508252356183.png)
    ![image.png](https://raw.githubusercontent.com/kyriekevin/img_auto/main/Obsidian/202508252356309.png)

  - ç²¾åº¦å¯¹æ¯”

    | Datasets  | Opencompass | Official | Deviation |
    | --------- | ----------- | -------- | --------- |
    | GPQA      | 54.55       | 62       | -7.45     |
    | IFEval    | 82.44       | 85       | -2.56     |
    | Math 500  | 96.8        | 97.4     | -0.6      |
    | AIME 2024 | 80          | 76       | +4        |
