---
title: >-
  On the Generalization of SFT: A Reinforcement Learning Perspective with Reward
  Rectification
date: 2025-08-18T00:00:00.000Z
tags:
  - sft
category: paper
venue: arXiv
authors: zyz
---
# DFT

## ğŸ“š Table of Contents

- [ğŸ“– Paper Info](#-paper-info)
- [ğŸ“ Summary](#-summary)
- [ğŸ”‘ Key Contributions](#-key-contributions)
- [ğŸ§© Method](#-method)
- [ğŸ“Š Experiments](#-experiments)
- [ğŸ’¬ Personal Insights](#-personal-insights)
- [ğŸ”— Related Papers](#-related-papers)

---

## ğŸ“– Paper Info

- **Title:** On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification
- **Venue:** arXiv preprint
- **Paper Link:** [https://arxiv.org/abs/2508.05629](https://arxiv.org/abs/2508.05629)
- **Publication Date:** 2025-08-07
- **Code:**([https://github.com/yongliang-wu/DFT](https://github.com/yongliang-wu/DFT))

---

## ğŸ“ Summary

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºåŠ¨æ€å¾®è°ƒï¼ˆDynamic Fine-Tuning, DFTï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹LLMåœ¨ç›‘ç£å¾®è°ƒSFTè¿‡ç¨‹ä¸­æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ã€‚å°½ç®¡SFTå› å…¶ç®€å•é«˜æ•ˆè€Œè¢«å¹¿æ³›åº”ç”¨ï¼Œä½†å…¶æ€§èƒ½é€šå¸¸ä¸åŠæ›´ä¸ºå¤æ‚çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³• ã€‚é€šè¿‡æ•°å­¦åˆ†æï¼Œå°†æ ‡å‡†SFTçš„æ¢¯åº¦æ›´æ–°è¿‡ç¨‹é‡æ–°è¯ é‡Šä¸ºä¸€ç§ç‰¹æ®Šçš„ç¦»çº¿ç­–ç•¥æ¢¯åº¦ï¼ˆoffline policy gradientï¼‰ç®—æ³•ã€‚è¯¥åˆ†ææ­ç¤ºäº†SFTä¸­éšå«ç€ä¸€ä¸ªæœ‰é—®é¢˜çš„å¥–åŠ±ç»“æ„ï¼šå…¶å¥–åŠ±å€¼ä¸æ¨¡å‹å¯¹ä¸“å®¶è¡Œä¸ºï¼ˆexpert actionï¼‰çš„é¢„æµ‹æ¦‚ç‡æˆåæ¯”ã€‚è¿™ç§â€œåå‘æ¦‚ç‡åŠ æƒâ€ä¼šå¯¼è‡´æ¢¯åº¦æ–¹å·®æ— ç•Œï¼Œä»è€Œå¼•å‘è®­ç»ƒä¸ç¨³å®šå’Œæ³›åŒ–èƒ½åŠ›å·®ç­‰é—®é¢˜ã€‚

ä¸ºçº æ­£è¿™ä¸€ç¼ºé™·ï¼ŒDFTæ–¹æ³•è¢«æå‡ºã€‚å®ƒé€šè¿‡ä¸€ä¸ªç®€å•çš„ä¿®æ”¹â€”â€”åœ¨è®¡ç®—æŸå¤±æ—¶ï¼Œå°†æ¯ä¸ªè¯å…ƒï¼ˆtokenï¼‰çš„æŸå¤±é¡¹ä¹˜ä»¥è¯¥è¯å…ƒçš„é¢„æµ‹æ¦‚ç‡â€”â€”æ¥åŠ¨æ€åœ°é‡æ–°ç¼©æ”¾SFTçš„ç›®æ ‡å‡½æ•°ã€‚è¿™ä¸€æ“ä½œä»æ ¹æœ¬ä¸Šâ€œä¿®æ­£â€äº†SFTå†…åœ¨çš„ç—…æ€å¥–åŠ±ç»“æ„ï¼Œä½¿å…¶è½¬å˜ä¸ºä¸€ä¸ªå¯¹æ‰€æœ‰ä¸“å®¶è¡Œä¸ºéƒ½ç»™äºˆæ’å®šå¥–åŠ±çš„ã€æ›´ç¨³å¥çš„ä¼˜åŒ–ç›®æ ‡

---

## ğŸ”‘ Key Contributions

- **SFTä¸RLçš„ç†è®ºç»Ÿä¸€**ï¼šå»ºç«‹äº†æ ‡å‡†SFTæ¢¯åº¦ä¸ç¦»çº¿ç­–ç•¥æ¢¯åº¦ä¹‹é—´çš„æ•°å­¦ç­‰ä»·å…³ç³»ã€‚ä»¥å¾€çš„ç ”ç©¶è™½ç„¶æŒ‡å‡ºäº†ä¸¤è€…é—´çš„æ™®éè”ç³»ï¼Œä½†æœªèƒ½æ­ç¤ºå…¶å†…åœ¨æœºåˆ¶ã€‚æŒ‡å‡ºSFTçš„æ³›åŒ–ç“¶é¢ˆæºäºå…¶æ¢¯åº¦ä¸­ä¸€ä¸ªéšå¼çš„â€œåå‘æ¦‚ç‡åŠ æƒé¡¹â€ï¼ˆå³å¥–åŠ±ä¸ $1/\pi_{\theta}$ æˆæ­£æ¯”ï¼‰ï¼Œè¿™ä¸ªé¡¹å¯¼è‡´äº†ç¨€ç–ä¸”ç—…æ€çš„å¥–åŠ±ç»“æ„ï¼Œæ˜¯è®­ç»ƒä¸ç¨³å®šçš„æ ¹æºã€‚

- **æå‡ºåŠ¨æ€å¾®è°ƒï¼ˆDFTï¼‰æ–¹æ³•**ï¼šæå‡ºäº†ä¸€ç§åä¸ºåŠ¨æ€å¾®è°ƒï¼ˆDFTï¼‰çš„åˆ›æ–°æ–¹æ³•ï¼Œæ—¨åœ¨ä»æ ¹æœ¬ä¸Šä¿®æ­£SFTçš„å†…åœ¨ç¼ºé™·ã€‚DFTé€šè¿‡å°†æ¯ä¸ªè¯å…ƒçš„æŸå¤±å‡½æ•°ä¹˜ä»¥å…¶è‡ªèº«çš„é¢„æµ‹æ¦‚ç‡ï¼Œæœ‰æ•ˆåœ°æŠµæ¶ˆäº†å‰è¿°çš„ç—…æ€åŠ æƒé¡¹ï¼Œä»è€Œå°†éšå¼å¥–åŠ±ä¿®æ­£ä¸ºä¸€ä¸ªæ’å®šä¸º1çš„ã€è¡Œä¸ºè‰¯å¥½çš„ä¿¡å·ã€‚

---

## ğŸ§© Method

### ç†è®ºä¹‹æ¡¥ï¼šå°†SFTé‡æ–°è¯ é‡Šä¸ºç­–ç•¥æ¢¯åº¦æ–¹æ³•

æ ‡å‡†çš„SFTæ—¨åœ¨é€šè¿‡æœ€å¤§åŒ–ä¸“å®¶æ¼”ç¤ºæ•°æ®é›† $D = \{(x, y^*)\}$ çš„ä¼¼ç„¶æ¥è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå…¶ç›®æ ‡æ˜¯æ¨¡ä»¿ä¸“å®¶çš„è¡Œä¸ºã€‚è¿™é€šå¸¸é€šè¿‡æœ€å°åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNegative Log-Likelihood, NLLï¼‰æ¥å®ç°ï¼Œç›®æ ‡å‡½æ•° $L_{SFT}(\theta)$ å®šä¹‰å¦‚ä¸‹ï¼š
$$L_{SFT}(\theta) = - \mathbb{E}_{(x, y^*) \sim D} \left[ \sum_{i=1}^{|y^*|} \log P_{\theta}(y_i^* | x, y_{<i}^*) \right]$$
å…¶ä¸­ï¼Œ$y_i^*$ æ˜¯ä¸“å®¶åºåˆ—ä¸­çš„ç¬¬ $i$ ä¸ªè¯å…ƒï¼Œ$y_{<i}^*$ æ˜¯å…¶å‰é¢çš„è¯å…ƒåºåˆ—ã€‚ä¸ºäº†ç®€åŒ–è¡¨ç¤ºï¼Œæˆ‘ä»¬å°†æ¨¡å‹ $P_{\theta}$ è§†ä¸ºç­–ç•¥ $\pi_{\theta}$ï¼Œå°†ä¸“å®¶è¡Œä¸º $y_i^*$ è§†ä¸ºåŠ¨ä½œ $a_i$ï¼Œå°†ä¸Šä¸‹æ–‡ $(x, y_{<i}^*)$ è§†ä¸ºçŠ¶æ€ $s_i$ã€‚äºæ˜¯ï¼ŒSFTçš„ç›®æ ‡å‡½æ•°å¯ä»¥é‡å†™ä¸ºï¼š
$$L_{SFT}(\theta) = - \mathbb{E}_{(s_i, a_i) \sim D} [\log \pi_{\theta}(a_i | s_i)]$$ä¸ºäº†æœ€å°åŒ–è¿™ä¸ªæŸå¤±å‡½æ•°ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œéœ€è¦è®¡ç®—å…¶å…³äºæ¨¡å‹å‚æ•° $\theta$ çš„æ¢¯åº¦ï¼š$$\nabla_{\theta} L_{SFT}(\theta) = - \mathbb{E}_{(s_i, a_i) \sim D} [\nabla_{\theta} \log \pi_{\theta}(a_i | s_i)]$$
è¿™ä¸ªæ¢¯åº¦å½¢å¼ä¸å¼ºåŒ–å­¦ä¹ ä¸­çš„ç­–ç•¥æ¢¯åº¦ï¼ˆPolicy Gradient, PGï¼‰å®šç†åœ¨ç»“æ„ä¸Šé«˜åº¦ç›¸ä¼¼ã€‚ç­–ç•¥æ¢¯åº¦å®šç†æŒ‡å‡ºï¼Œå¯¹äºä¸€ä¸ªæœ€å¤§åŒ–æœŸæœ›å¥–åŠ± $J(\theta) = \mathbb{E}_{\tau \sim \pi_{\theta}}$ çš„ç›®æ ‡ï¼Œå…¶æ¢¯åº¦ä¸ºï¼š
$$\nabla_{\theta} J(\theta) = \mathbb{E}_{(s_t, a_t) \sim \pi_{\theta}}$$
æœ¬æ–‡çš„æ ¸å¿ƒæ´è§åœ¨äºï¼ŒSFTçš„æ¢¯åº¦æ›´æ–°å¯ä»¥è¢«ç²¾ç¡®åœ°è§£é‡Šä¸ºä¸€ä¸ªå…·æœ‰ç‰¹å®šéšå¼å¥–åŠ± $R_{SFT}$ çš„ç¦»çº¿ç­–ç•¥æ¢¯åº¦æ›´æ–°ã€‚é€šè¿‡å°†SFTçš„æ¢¯åº¦å½¢å¼ä¸ç­–ç•¥æ¢¯åº¦å®šç†è¿›è¡Œå¯¹é½ï¼Œè®ºæ–‡æ­ç¤ºäº†è¿™ä¸ªéšå¼å¥–åŠ±è¢«ç²¾ç¡®åœ°å®šä¹‰ä¸ºï¼š
$$R_{SFT}(s_i, a_i) = \frac{1}{\pi_{\theta}(a_i | s_i)}$$
è¿™ä¸ªå¥–åŠ±ç»“æ„å­˜åœ¨ä¸¤ä¸ªè‡´å‘½ç¼ºé™·ï¼š

1. **åæ¯”å…³ç³»**ï¼šå¥–åŠ±çš„å¤§å°ä¸æ¨¡å‹å¯¹ä¸“å®¶è¡Œä¸ºçš„é¢„æµ‹æ¦‚ç‡æˆåæ¯”ã€‚è¿™æ„å‘³ç€ï¼Œå½“æ¨¡å‹å¯¹æŸä¸ªè¯å…ƒçš„é¢„æµ‹è¶Šä¸ç¡®å®šï¼ˆå³ $\pi_{\theta}$ è¶Šå°ï¼‰ï¼Œä¸€æ—¦é¢„æµ‹æ­£ç¡®ï¼Œå®ƒè·å¾—çš„å¥–åŠ±ä¿¡å·åè€Œä¼šå‘ˆæŒ‡æ•°çº§å¢é•¿ã€‚
2. **æ–¹å·®æ— ç•Œ**ï¼šå½“ $\pi_{\theta}(a_i | s_i) \to 0$ æ—¶ï¼Œ$R_{SFT} \to \infty$ã€‚å½“æ¨¡å‹å¯¹æŸä¸ªä¸“å®¶è¯å…ƒçš„é¢„æµ‹æ¦‚ç‡$\pi_\theta$éå¸¸ä½æ—¶ï¼ˆå³æ¨¡å‹å¯¹è¿™ä¸€æ­¥æ„Ÿåˆ°â€œæ„å¤–â€æˆ–â€œä¸ç¡®å®šâ€ï¼‰ï¼Œå…¶å¯¹åº”çš„éšæ€§å¥–åŠ±ä¼šå˜å¾—æå…¶å·¨å¤§ã€‚è¿™ä¼šå¯¼è‡´æ¢¯åº¦æ›´æ–°çš„æ–¹å·®è¶‹äºæ— ç©·å¤§ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šä¸ºäº†æ‹Ÿåˆè¿™äº›ä½æ¦‚ç‡çš„â€œå¼‚å¸¸ç‚¹â€è€Œè¿›è¡Œå‰§çƒˆä¸”ä¸ç¨³å®šçš„å‚æ•°è°ƒæ•´ï¼Œä»è€Œç ´åäº†å­¦ä¹ è¿‡ç¨‹çš„å¹³ç¨³æ€§ã€‚

### å¥–åŠ±ä¿®æ­£ï¼šDFTçš„è§£å†³æ–¹æ¡ˆåŠå…¶æœºåˆ¶

ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼ŒDFTå¯¹æ ‡å‡†SFTçš„æŸå¤±å‡½æ•°å¼•å…¥äº†ä¸€ä¸ªåŠ¨æ€ç¼©æ”¾å› å­ã€‚DFTçš„æŸå¤±å‡½æ•° $L_{DFT}(\theta)$ å®šä¹‰å¦‚ä¸‹ï¼š
$$L_{DFT}(\theta) = - \mathbb{E}_{(x, y^*) \sim D} \left[ \sum_{i=1}^{|y^*|} \pi_{\theta}(y_i^* | x, y_{<i}^*) \cdot \log P_{\theta}(y_i^* | x, y_{<i}^*) \right]$$
åœ¨å®é™…è®¡ç®—ä¸­ï¼Œç”¨äºç¼©æ”¾çš„æ¦‚ç‡é¡¹ $\pi_{\theta}$ æ˜¯ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»ï¼ˆdetachï¼‰å‡ºæ¥çš„ï¼Œè¿™æ„å‘³ç€åœ¨åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦æ—¶ï¼Œå®ƒè¢«è§†ä¸ºä¸€ä¸ªå¸¸æ•°æƒé‡ï¼Œå› æ­¤ä¸ä¼šå¯¹ $\log P_{\theta}$ æœ¬èº«çš„æ¢¯åº¦äº§ç”Ÿå½±å“ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬æ¥æ¨å¯¼DFTç›®æ ‡çš„æ¢¯åº¦ã€‚ç”±äº $\pi_{\theta}(a_i | s_i)$ é¡¹è¢«åˆ†ç¦»ï¼Œæ¢¯åº¦è®¡ç®—å¦‚ä¸‹ï¼š
$$\nabla_{\theta} L_{DFT}(\theta) = - \mathbb{E}_{(s_i, a_i) \sim D} [\pi_{\theta}(a_i | s_i) \cdot \nabla_{\theta} \log \pi_{\theta}(a_i | s_i)]$$
å°†è¿™ä¸ªæ¢¯åº¦å½¢å¼ä¸ç­–ç•¥æ¢¯åº¦å®šç† $\mathbb{E}$ è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œè¿™ä¸ªæ–°çš„ç¼©æ”¾å› å­ $\pi_{\theta}(a_i | s_i)$ å……å½“äº†æ–°çš„å¥–åŠ±ä¿¡å·ã€‚å› æ­¤ï¼ŒDFTçš„éšå¼å¥–åŠ± $R_{DFT}$ ä¸ºï¼š
$$R_{DFT}(s_i, a_i) = \pi_{\theta}(a_i | s_i) \cdot R_{SFT}(s_i, a_i) = \pi_{\theta}(a_i | s_i) \cdot \frac{1}{\pi_{\theta}(a_i | s_i)} = 1$$
è¿™ä¸€ç®€å•çš„ä¹˜æ³•æ“ä½œæœ‰æ•ˆåœ°â€œæŠµæ¶ˆâ€æˆ–â€œä¸­å’Œâ€äº†SFTä¸­å›ºæœ‰çš„ç—…æ€åå‘æ¦‚ç‡åŠ æƒé—®é¢˜ã€‚å…¶ç»“æœæ˜¯ï¼Œå¯¹äºæ¯ä¸€ä¸ªä¸“å®¶è¯å…ƒï¼Œæ— è®ºæ¨¡å‹å½“å‰çš„ç­–ç•¥å¦‚ä½•ï¼Œå…¶è·å¾—çš„å¥–åŠ±ä¿¡å·éƒ½æ˜¯ä¸€ä¸ªæ’å®šçš„ã€è¡Œä¸ºè‰¯å¥½çš„å€¼â€œ1â€ã€‚è¿™ä½¿å¾—ä¼˜åŒ–ç›®æ ‡è½¬å˜ä¸ºä»¥ç¨³å®šä¸”å‡åŒ€åŠ æƒçš„æ¢¯åº¦æ¥å­¦ä¹ ä¸“å®¶åˆ†å¸ƒï¼Œä»è€Œæå¤§åœ°ç¨³å®šäº†è®­ç»ƒè¿‡ç¨‹ã€‚

è¯¥æ–¹æ³•çš„ä¼˜é›…ä¹‹å¤„åœ¨äºå…¶å®ç°ä¸Šçš„æè‡´ç®€æ´ï¼Œä½œè€…å¼ºè°ƒè¿™ä»…ä»…æ˜¯ä¸€è¡Œä»£ç çš„æ”¹åŠ¨ï¼š
`loss = loss * torch.softmax(shift_logits, dim=-1).gather(1, shift_labels.unsqueeze(-1)).squeeze(-1).detach()`

ä»æ›´æ·±å±‚æ¬¡çœ‹ï¼ŒSFTä½œä¸ºä¸€ç§è¡Œä¸ºå…‹éš†æ–¹æ³•ï¼Œå¤©ç„¶ä¼šå—åˆ°åå˜é‡åç§»ï¼ˆcovariate shiftï¼‰é—®é¢˜çš„å½±å“ã€‚å¼ºåŒ–å­¦ä¹ ä¸­é€šå¸¸ä½¿ç”¨é‡è¦æ€§é‡‡æ ·ï¼ˆimportance samplingï¼‰æ¥ä¿®æ­£è¿™ç§åˆ†å¸ƒä¸åŒ¹é…ã€‚SFTæ¢¯åº¦ä¸­éšå«çš„ $1/\pi_{\theta}$ å¥–åŠ±é¡¹ï¼Œå½¢å¼ä¸Šç±»ä¼¼äºç¦»çº¿ç­–ç•¥ä¿®æ­£ä¸­çš„ä¸€ä¸ªéƒ¨åˆ†ï¼Œä½†å…¶åº”ç”¨æ–¹å¼ä¸å½“ï¼Œåè€Œå¯¼è‡´äº†æ–¹å·®çˆ†ç‚¸ã€‚DFTé€šè¿‡ä¹˜ä»¥ $\pi_{\theta}$ æ¥æŠµæ¶ˆè¿™ä¸€é¡¹ï¼Œå¯ä»¥è¢«çœ‹ä½œæ˜¯å¯¹SFTå†…éƒ¨ä¸€ä¸ªæœ‰ç¼ºé™·çš„ã€éšå¼çš„ç¦»çº¿ä¿®æ­£æœºåˆ¶çš„çº æ­£ã€‚å®ƒæ²¡æœ‰å¼•å…¥å¤æ‚çš„æ¦‚ç‡æ¯”ç‡ï¼Œè€Œæ˜¯å°†ç›®æ ‡ç®€åŒ–ä¸ºä¸€ä¸ªç¨³å®šçš„ã€ç±»ä¼¼åœ¨çº¿ï¼ˆon-policyï¼‰çš„æ›´æ–°è¿‡ç¨‹ï¼Œå…¶ä¸­æ¯ä¸ªä¸“å®¶è¡Œä¸ºéƒ½è¢«èµ‹äºˆäº†ç»Ÿä¸€çš„æ­£é¢å¥–åŠ±ã€‚

---

## ğŸ“Š Experiments

### å®éªŒè®¾è®¡

- **æ¨¡å‹**ï¼šå®éªŒé‡‡ç”¨äº†ä¸€ç³»åˆ—å½“å‰å…ˆè¿›çš„å¼€æºæ¨¡å‹ï¼Œæ¶µç›–äº†æ•°å­¦ä¸“ç”¨æ¨¡å‹ï¼ˆå¦‚Qwen2.5-Math-1.5B/7B, DeepSeekMath-7Bï¼‰å’Œé€šç”¨æ¨¡å‹ï¼ˆå¦‚LLaMA-3.2-3B, LLaMA-3.1-8Bï¼‰ï¼Œä»¥éªŒè¯æ–¹æ³•çš„æ™®é€‚æ€§ã€‚
- **æ•°æ®é›†**ï¼šè®­ç»ƒæ•°æ®ä½¿ç”¨äº†NuminaMath CoTæ•°æ®é›†çš„ä¸€ä¸ª10ä¸‡æ¡æ ·æœ¬çš„å­é›†ã€‚è¯„ä¼°åˆ™åœ¨ä¸€ç³»åˆ—å…¬è®¤çš„ã€èƒ½æµ‹è¯•æ¨¡å‹æ·±åº¦æ¨ç†å’Œæ³›åŒ–èƒ½åŠ›çš„æ•°å­¦åŸºå‡†ä¸Šè¿›è¡Œï¼ŒåŒ…æ‹¬Math500ã€Minerva Mathã€Olympiad Benchã€AIME 2024å’ŒAMC 2023ã€‚
- **åŸºçº¿æ–¹æ³•**ï¼šDFTä¸»è¦ä¸æ ‡å‡†SFTè¿›è¡Œæ¯”è¾ƒã€‚åŒæ—¶ï¼Œä¸ºäº†æä¾›æ›´å¹¿é˜”çš„è§†è§’ï¼Œå®éªŒè¿˜åŒ…å«äº†ä¸åŒæœŸå·¥ä½œImportance-Weighted SFT (iw-SFT)çš„å¯¹æ¯”ï¼Œå¹¶åœ¨ä¸€ä¸ªç¦»çº¿RLåœºæ™¯ä¸­ï¼Œä¸DPOã€RFTã€PPOå’ŒGRPOç­‰å¼ºåŸºçº¿è¿›è¡Œäº†æ¯”è¾ƒã€‚

### æ ¸å¿ƒæ€§èƒ½åˆ†æï¼šDFT vs. SFT

å®éªŒç»“æœæ¸…æ™°åœ°è¡¨æ˜ï¼Œåœ¨æ‰€æœ‰æµ‹è¯•æ¨¡å‹å’ŒåŸºå‡†ä¸Šï¼ŒDFTçš„æ€§èƒ½éƒ½æ˜¾è‘—ä¼˜äºæ ‡å‡†SFTã€‚å°¤å…¶æ˜¯åœ¨é‚£äº›SFTè¡¨ç°ä¸ä½³ç”šè‡³äº§ç”Ÿè´Ÿé¢å½±å“ï¼ˆå³æ€§èƒ½ä¸‹é™ï¼‰çš„é«˜éš¾åº¦æ•°æ®é›†ä¸Šï¼ŒDFTçš„ä¼˜åŠ¿æ›´ä¸ºçªå‡ºï¼Œè¿™æœ‰åŠ›åœ°è¯æ˜äº†å…¶åœ¨æ”¹å–„æ³›åŒ–å’Œé¿å…è¿‡æ‹Ÿåˆæ–¹é¢çš„èƒ½åŠ›

| Model                   | Math500   | Minerva Math | Olympiad Bench | AIME24   | AMC23     | Avg.      |
| :---------------------- | :-------- | :----------- | :------------- | :------- | :-------- | :-------- |
| LLaMA-3.2-3B w/SFT      | 8.65      | 2.38         | 2.06           | 0.00     | 3.13      | 3.24      |
| LLaMA-3.2-3B w/DFT      | **12.79** | **2.84**     | **2.90**       | **0.83** | **3.91**  | **4.65**  |
| LLaMA-3.1-8B w/SFT      | 16.85     | 5.78         | 3.88           | 0.00     | 5.16      | 6.33      |
| LLaMA-3.1-8B w/DFT      | **27.44** | **8.26**     | **6.94**       | **0.41** | **12.03** | **11.02** |
| DeepSeekMath-7B w/SFT   | 26.83     | 7.26         | 6.33           | 0.41     | 8.28      | 9.82      |
| DeepSeekMath-7B w/DFT   | **41.46** | **16.79**    | **15.00**      | **1.24** | **16.25** | **18.15** |
| Qwen2.5-Math-1.5B w/SFT | 43.76     | 13.04        | 12.63          | 1.87     | 18.75     | 18.01     |
| Qwen2.5-Math-1.5B w/DFT | **64.89** | **20.94**    | **27.08**      | **6.87** | **38.13** | **31.58** |
| Qwen2.5-Math-7B w/SFT   | 53.96     | 16.66        | 18.93          | 2.48     | 26.09     | 23.62     |
| Qwen2.5-Math-7B w/DFT   | **68.20** | **30.16**    | **33.83**      | **8.56** | **45.00** | **37.15** |

### åœ¨RLç¯å¢ƒä¸‹çš„å¯¹æ¯”åˆ†æ

åœ¨ä¸€ä¸ªæ¢ç´¢æ€§çš„ç¦»çº¿RLè®¾å®šä¸­ï¼ŒDFTå†æ¬¡å–å¾—äº†æœ€ä½³çš„æ•´ä½“æ€§èƒ½ã€‚ä»¥Qwen2.5-Math-1.5Bæ¨¡å‹ä¸ºä¾‹ï¼ŒDFTçš„å¹³å‡åˆ†è¾¾åˆ°äº†35.43ï¼Œä¸ä»…è¶…è¶Šäº†DPOï¼ˆ23.20ï¼‰å’ŒRFTï¼ˆ23.97ï¼‰ç­‰å¼ºå¤§çš„ç¦»çº¿RLæ–¹æ³•ï¼Œç”šè‡³ä¼˜äºPPOï¼ˆ28.66ï¼‰å’ŒGRPOï¼ˆ32.00ï¼‰ç­‰éœ€è¦åœ¨çº¿é‡‡æ ·ã€æ›´ä¸ºå¤æ‚çš„åœ¨çº¿RLç®—æ³•ã€‚

| Setting                         | Math500   | Minerva Math | Olympiad Bench | AIME24   | AMC23     | Avg.      |
| :------------------------------ | :-------- | :----------- | :------------- | :------- | :-------- | :-------- |
| Qwen2.5-Math-1.5B w/SFT         | 43.14     | 11.64        | 13.41          | 1.03     | 14.84     | 16.81     |
| Qwen2.5-Math-1.5B w/DPO Offline | 46.89     | 11.53        | 22.86          | 4.58     | 30.16     | 23.20     |
| Qwen2.5-Math-1.5B w/RFT Offline | 48.23     | 14.19        | 22.29          | 4.37     | 30.78     | 23.97     |
| Qwen2.5-Math-1.5B w/PPO Online  | 56.10     | 15.41        | 26.33          | 7.50     | 37.97     | 28.66     |
| Qwen2.5-Math-1.5B w/GRPO Online | 62.86     | 18.93        | 28.62          | **8.34** | 41.25     | 32.00     |
| Qwen2.5-Math-1.5B w/DFT Offline | **64.71** | **25.16**    | **30.93**      | 7.93     | **48.44** | **35.43** |

### æ¨¡å‹è¡Œä¸ºä¸æ¶ˆèç ”ç©¶

- **â€œæåŒ–æ•ˆåº”â€**ï¼šå¯¹è¯å…ƒæ¦‚ç‡åˆ†å¸ƒçš„åˆ†ææ˜¾ç¤ºï¼ŒDFTä¼šå¼•å¯¼æ¨¡å‹äº§ç”Ÿä¸€ç§â€œæåŒ–æ•ˆåº”â€ï¼Œå³æ˜¾è‘—æå‡ä¸€éƒ¨åˆ†å…³é”®è¯­ä¹‰è¯å…ƒçš„æ¦‚ç‡ï¼ŒåŒæ—¶ä¸»åŠ¨æŠ‘åˆ¶å…¶ä»–ï¼ˆå¦‚è¯­æ³•åŠŸèƒ½æ€§ï¼‰è¯å…ƒçš„æ¦‚ç‡ï¼Œå½¢æˆåŒå³°åˆ†å¸ƒã€‚è¿™ä¸SFTå€¾å‘äºç»Ÿä¸€æå‡æ‰€æœ‰è¯å…ƒæ¦‚ç‡çš„è¡Œä¸ºå½¢æˆé²œæ˜å¯¹æ¯”ï¼Œè¡¨æ˜DFTé‡‡ç”¨äº†ä¸€ç§æ›´ç²¾ç»†çš„å­¦ä¹ ç­–ç•¥ï¼Œè¿™å¯èƒ½ä¹Ÿæ˜¯å…¶æ³›åŒ–èƒ½åŠ›æ›´å¼ºçš„åŸå› ä¹‹ä¸€ã€‚
- **è¶…å‚æ•°é²æ£’æ€§**ï¼šæ¶ˆèå®éªŒè¡¨æ˜ï¼Œåœ¨ä¸åŒçš„å­¦ä¹ ç‡å’Œæ‰¹é‡å¤§å°ä¸‹ï¼ŒDFTçš„æ€§èƒ½å§‹ç»ˆä¼˜äºSFTã€‚è¿™è¯æ˜äº†DFTçš„ä¼˜åŠ¿å¹¶éæºäºç‰¹å®šçš„è¶…å‚æ•°è°ƒä¼˜ï¼Œè€Œæ˜¯å…¶æ–¹æ³•æœ¬èº«çš„æ ¹æœ¬æ€§ä¼˜åŠ¿ã€‚

---

## ğŸ’¬ Personal Insights

### SFT-RLè°±ç³»ï¼šDFTçš„å®šä½

- **SFT (ç›‘ç£å¾®è°ƒ)**ï¼šå¯è§†ä¸ºæœ´ç´ çš„è¡Œä¸ºå…‹éš†ã€‚å…¶ç›®æ ‡çº¯ç²¹æ˜¯æ¨¡ä»¿ï¼Œå³æœ€å¤§åŒ–ä¸“å®¶åºåˆ—çš„æ¦‚ç‡ã€‚ä¼˜ç‚¹æ˜¯ç®€å•é«˜æ•ˆï¼Œä½†å…¶æ ¹æœ¬ç¼ºé™·åœ¨äºä¸€ä¸ªç—…æ€çš„éšå¼å¥–åŠ±ï¼Œå¯¼è‡´æ¨¡å‹å€¾å‘äºè®°å¿†è€Œéæ³›åŒ–ã€‚
- **RLHF (äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ )**ï¼šè¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„å¤šé˜¶æ®µä¼˜åŒ–è¿‡ç¨‹ã€‚å®ƒéœ€è¦è®­ç»ƒä¸€ä¸ªç‹¬ç«‹çš„å¥–åŠ±æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨PPOç­‰åœ¨çº¿RLç®—æ³•è¿›è¡Œç­–ç•¥ä¼˜åŒ–ã€‚ä¼˜ç‚¹æ˜¯èƒ½å¤Ÿæ¢ç´¢å¹¶å‘ç°æ¯”SFTæ³›åŒ–èƒ½åŠ›æ›´å¼ºçš„ç­–ç•¥ ï¼Œä½†ç¼ºç‚¹æ˜¯æµç¨‹å¤æ‚ã€è®¡ç®—æˆæœ¬é«˜ä¸”è®­ç»ƒä¸ç¨³å®šã€‚
- **DFT (åŠ¨æ€å¾®è°ƒ)**ï¼šDFTåœ¨è¿™ä¸¤ä¸ªæç«¯ä¹‹é—´å¼€è¾Ÿäº†ä¸€ä¸ªç‹¬ç‰¹çš„ä¸­é—´åœ°å¸¦ã€‚å®ƒä¿ç•™äº†SFTçš„ç®€æ´å’Œå•é˜¶æ®µé«˜æ•ˆæ€§ï¼Œä½†é€šè¿‡æ•°å­¦ä¸Šçš„ä¿®æ­£ï¼Œå¼•å…¥äº†RLçš„æ ¸å¿ƒåŸåˆ™â€”â€”ä¸€ä¸ªå®šä¹‰è‰¯å¥½çš„å¥–åŠ±ä¿¡å·ã€‚å®ƒåœ¨ä¸å¼•å…¥æ˜¾å¼å¥–åŠ±æ¨¡å‹æˆ–åœ¨çº¿é‡‡æ ·ç­‰å¤æ‚ç»„ä»¶çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†ç±»ä¼¼RLçš„æ³›åŒ–æ”¶ç›Šï¼Œå ªç§°ä¸€ç§â€œä¸¤å…¨å…¶ç¾â€çš„æ–¹æ³•ã€‚

### ä¸¤ç§åŠ æƒæ–¹æ¡ˆçš„è¾¨æï¼šDFT vs. Focal Loss

ä¸ºäº†æ›´æ·±å…¥åœ°ç†è§£DFTä¸­æŸå¤±åŠ æƒæœºåˆ¶çš„ç²¾å¦™ä¹‹å¤„ï¼Œå¯ä»¥å°†å…¶ä¸å¦ä¸€ä¸ªè‘—åçš„æŸå¤±å‡½æ•°â€”â€”ç„¦ç‚¹æŸå¤±ï¼ˆFocal Lossï¼‰è¿›è¡Œå¯¹æ¯”åˆ†æ ã€‚Focal Lossæœ€åˆè¢«æå‡ºç”¨äºè§£å†³å¯†é›†ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­æç«¯çš„å‰æ™¯-èƒŒæ™¯ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚

- **æ ¸å¿ƒç›®æ ‡ä¸åŒ**ï¼š

  - **Focal Loss**ï¼šå¯¹äºé‚£äº›æ¨¡å‹å·²ç»èƒ½å¤Ÿå¾ˆå¥½åˆ†ç±»çš„æ ·æœ¬ï¼ˆå³â€œç®€å•æ ·æœ¬â€ï¼Œptâ€‹å¾ˆé«˜ï¼‰ï¼Œè°ƒåˆ¶å› å­$(1-p_t)^\gamma$ä¼šå˜å¾—éå¸¸å°ï¼Œä»è€Œæå¤§åœ°**é™ä½è¿™äº›ç®€å•æ ·æœ¬å¯¹æ€»æŸå¤±çš„è´¡çŒ®**ã€‚è¿™æ ·ä¸€æ¥ï¼Œæ¨¡å‹çš„è®­ç»ƒå°†æ›´åŠ ä¸“æ³¨äºé‚£äº›éš¾ä»¥åˆ†ç±»çš„â€œå›°éš¾æ ·æœ¬â€ï¼ˆptâ€‹è¾ƒä½ï¼‰ï¼Œå³å°‘æ•°çš„æ­£æ ·æœ¬ï¼ˆç›®æ ‡ç‰©ä½“ï¼‰ã€‚
  - **DFT**ï¼šå…¶ç›®æ ‡æ˜¯ä¿®æ­£åºåˆ—ç”Ÿæˆä»»åŠ¡ä¸­ä¸€ä¸ª**ç—…æ€çš„éšå¼å¥–åŠ±ç»“æ„**ã€‚å®ƒå…³å¿ƒçš„ä¸æ˜¯è¯å…ƒé—´çš„ç±»åˆ«ä¸å¹³è¡¡ï¼Œè€Œæ˜¯ç”±åå‘æ¦‚ç‡å¥–åŠ±ä¿¡å·å¼•èµ·çš„è®­ç»ƒä¸ç¨³å®šé—®é¢˜ã€‚

- **æ•°å­¦å½¢å¼ä¸æœºåˆ¶ä¸åŒ**ï¼š
  - **Focal Loss**: $FL(p_t) = -\alpha_t(1 - p_t)^\gamma \log(p_t)$ ã€‚å…¶ç›®çš„æ˜¯é€šè¿‡**æŠ‘åˆ¶ç®€å•æ ·æœ¬**çš„æŸå¤±ï¼Œæ¥æ”¾å¤§ç¨€æœ‰å›°éš¾æ ·æœ¬çš„ä¿¡å·ã€‚
  - å…¶å…³é”®æ˜¯è°ƒåˆ¶å› å­ $(1 - p_t)^\gamma$ã€‚å½“æ ·æœ¬è¢«è½»æ¾åˆ†ç±»æ—¶ï¼ˆ$p_t \to 1$ï¼‰ï¼Œè¯¥å› å­è¶‹è¿‘äº0ï¼Œä»è€Œé™ä½å…¶æŸå¤±è´¡çŒ®ã€‚å½“æ ·æœ¬éš¾ä»¥åˆ†ç±»æ—¶ï¼ˆ$p_t \to 0$ï¼‰ï¼Œè¯¥å› å­æ¥è¿‘1ï¼ŒæŸå¤±ä¸å—å½±å“ã€‚å®ƒæ ¹æ®**åˆ†ç±»çš„éš¾æ˜“ç¨‹åº¦**è¿›è¡ŒåŠ æƒã€‚
  - **DFT**: $L_{DFT} = -p_t \cdot \log(p_t)$ï¼ˆç®€åŒ–å½¢å¼ï¼‰ã€‚å…¶ç›®çš„æ˜¯é€šè¿‡**æŠ‘åˆ¶å›°éš¾æ ·æœ¬**ï¼ˆä½ptâ€‹ï¼‰çš„æŸå¤±ï¼Œæ¥ç¨³å®šæ•´ä½“çš„æ¢¯åº¦æ›´æ–°ã€‚
    - å…¶å…³é”®æ˜¯ç¼©æ”¾å› å­ $p_t$ã€‚è¿™ä¸ªå› å­çš„å”¯ä¸€ç›®çš„æ˜¯åœ¨ä»£æ•°ä¸Š**æŠµæ¶ˆ**SFTæ¢¯åº¦ä¸­éšå¼çš„ $1/p_t$ å¥–åŠ±é¡¹ã€‚å®ƒå¹¶éä¸ºäº†åŒºåˆ†éš¾æ˜“æ ·æœ¬ï¼Œè€Œæ˜¯ä¸ºäº†å°†æ‰€æœ‰ä¸“å®¶æ ·æœ¬çš„å¥–åŠ±**å‡ç­‰åŒ–**ä¸ºä¸€ä¸ªæ’å®šå€¼1ã€‚å®ƒä¸ºäº†å®ç°**å¥–åŠ±çš„ç¨³å®šæ€§**è€Œè¿›è¡ŒåŠ æƒã€‚

è¿™ä¸€å¯¹æ¯”æ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»çš„ç°è±¡ï¼šä¸¤ç§æˆåŠŸçš„æŸå¤±åŠ æƒæ–¹æ¡ˆï¼Œé‡‡ç”¨äº†å‡ ä¹ç›¸åçš„ç­–ç•¥ã€‚Focal Lossæå‡äº†å›°éš¾æ ·æœ¬çš„ç›¸å¯¹æƒé‡ï¼Œè€ŒDFTé™ä½äº†å›°éš¾æ ·æœ¬çš„ç›¸å¯¹æƒé‡ã€‚è¿™ç§çœ‹ä¼¼çŸ›ç›¾çš„ç°è±¡èƒŒåï¼Œåæ˜ äº†å¯¹ä¸åŒé—®é¢˜é¢†åŸŸæ ¸å¿ƒç“¶é¢ˆçš„ç²¾å‡†æŠŠæ¡ã€‚

- åœ¨å¯†é›†ç›®æ ‡æ£€æµ‹ä¸­ï¼Œå­¦ä¹ çš„**ç“¶é¢ˆæ˜¯ä¿¡å™ªæ¯”**ã€‚ç»å¤§å¤šæ•°çš„â€œç®€å•èƒŒæ™¯â€æ ·æœ¬æ„æˆäº†å‹å€’æ€§çš„å™ªå£°ï¼Œæ·¹æ²¡äº†å°‘æ•°â€œå›°éš¾å‰æ™¯â€æ ·æœ¬çš„ä¿¡å·ã€‚å› æ­¤ï¼ŒFocal Lossé€šè¿‡æŠ‘åˆ¶å™ªå£°ï¼ˆç®€å•æ ·æœ¬ï¼‰æ¥æ”¾å¤§ä¿¡å·ï¼ˆå›°éš¾æ ·æœ¬ï¼‰ï¼Œè§£å†³äº†ä¿¡å·æ£€æµ‹çš„é—®é¢˜ã€‚
- åœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªå›å½’ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå­¦ä¹ çš„**ç“¶é¢ˆæ˜¯ä¼˜åŒ–ç¨³å®šæ€§**ã€‚é‚£äº›æ¨¡å‹éš¾ä»¥é¢„æµ‹çš„â€œå›°éš¾è¯å…ƒâ€ï¼ˆå³ä½¿å®ƒä»¬æ˜¯æ­£ç¡®ç­”æ¡ˆï¼‰ä¼šäº§ç”Ÿå·¨å¤§çš„æ¢¯åº¦ï¼Œå½¢æˆç ´åæ€§çš„â€œæ¢¯åº¦å™ªå£°â€ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•ç¨³å®šæ”¶æ•›åˆ°æ³›åŒ–èƒ½åŠ›å¼ºçš„è§£ã€‚å› æ­¤ï¼ŒDFTé€šè¿‡æŠ‘åˆ¶è¿™ç§æ¢¯åº¦å™ªå£°ï¼ˆå›°éš¾æ ·æœ¬ï¼‰ï¼Œæ¥ä¿è¯å­¦ä¹ è¿‡ç¨‹çš„å¹³ç¨³æ€§ï¼Œè§£å†³äº†ä¼˜åŒ–è·¯å¾„çš„é—®é¢˜ã€‚

è¿™ä¸ªå¯¹æ¯”åˆ†æè¡¨æ˜ï¼Œâ€œæ ¹æ®æ¦‚ç‡å¯¹æŸå¤±è¿›è¡ŒåŠ æƒâ€è¿™ä¸€æ€æƒ³æœ¬èº«å¹¶éä¸‡èƒ½è¯ï¼Œå…¶å…·ä½“çš„å‡½æ•°å½¢å¼å’Œä½œç”¨æœºåˆ¶å¿…é¡»ä¸å¾…è§£å†³é—®é¢˜çš„æ ¸å¿ƒçŸ›ç›¾ç›¸åŒ¹é…ã€‚DFTå’ŒFocal Lossçš„æˆåŠŸï¼Œæ°æ°åœ¨äºå®ƒä»¬éƒ½è¯†åˆ«å¹¶ç²¾ç¡®åœ°è°ƒåˆ¶äº†å„è‡ªé¢†åŸŸä¸­ä¿¡æ¯é‡æœ€ä½ã€ä½†å¯¹è®­ç»ƒè¿‡ç¨‹å¹²æ‰°æœ€å¤§çš„é‚£éƒ¨åˆ†æ•°æ®åˆ†å¸ƒçš„è´¡çŒ®ã€‚DFTé€šè¿‡ä¼˜å…ˆå­¦ä¹ æ¨¡å‹å·²ç»èƒ½å¤Ÿè¾ƒå¥½ç†è§£çš„éƒ¨åˆ†ï¼Œé¼“åŠ±å…¶æ„å»ºä¸€ä¸ªè¿è´¯ã€è‡ªæ´½çš„å†…éƒ¨çŸ¥è¯†ä½“ç³»ï¼Œè€Œä¸æ˜¯å¼ºè¿«å®ƒå»æ­»è®°ç¡¬èƒŒé‚£äº›ä¸ä¹‹å½“å‰ç†è§£ç›¸æ‚–çš„â€œä¾‹å¤–æƒ…å†µâ€ã€‚

### SFTä¸DFTæŸå¤±å‡½æ•°çš„ä¿¡æ¯è®ºè¯ é‡Š

#### SFTæŸå¤±ï¼šæœ€å°åŒ–KLæ•£åº¦

ä»ä¿¡æ¯è®ºçš„è§’åº¦æ¥çœ‹ï¼ŒSFTæ‰€ä½¿ç”¨çš„æ ‡å‡†äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå…¶æ ¹æœ¬ç›®æ ‡æ˜¯æœ€å°åŒ–ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚
åœ¨æœºå™¨å­¦ä¹ çš„åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªå…³é”®çš„æ¦‚ç‡åˆ†å¸ƒï¼š

1. **çœŸå®æ•°æ®åˆ†å¸ƒ P**ï¼šåœ¨SFTä¸­ï¼Œè¿™é€šå¸¸ç”±è®­ç»ƒæ•°æ®é›†çš„ç»éªŒåˆ†å¸ƒæ¥è¡¨ç¤ºã€‚å¯¹äºæ¯ä¸ªè¯å…ƒçš„é¢„æµ‹ï¼ŒçœŸå®åˆ†å¸ƒæ˜¯ä¸€ä¸ªone-hotå‘é‡ï¼Œå³æ­£ç¡®è¯å…ƒçš„æ¦‚ç‡ä¸º1ï¼Œå…¶ä½™æ‰€æœ‰è¯å…ƒçš„æ¦‚ç‡ä¸º0ã€‚
2. **æ¨¡å‹é¢„æµ‹åˆ†å¸ƒ Q**ï¼šè¿™æ˜¯æ¨¡å‹ï¼ˆç”±å‚æ•°$\theta$å†³å®šï¼‰åœ¨ç»™å®šä¸Šä¸‹æ–‡åï¼Œå¯¹ä¸‹ä¸€ä¸ªè¯å…ƒçš„é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒã€‚

äº¤å‰ç†µï¼ˆCross-Entropyï¼‰$H(P, Q)$è¡¡é‡äº†ä½¿ç”¨åŸºäºåˆ†å¸ƒ$Q$çš„ç¼–ç æ–¹å¼æ¥ç¼–ç æ¥è‡ªçœŸå®åˆ†å¸ƒPçš„æ ·æœ¬æ—¶ï¼Œæ‰€éœ€è¦çš„å¹³å‡æ¯”ç‰¹æ•° ã€‚åœ¨SFTçš„åœºæ™¯ä¸‹ï¼Œç”±äºPæ˜¯one-hotåˆ†å¸ƒï¼ˆå‡è®¾æ­£ç¡®ç±»åˆ«æ˜¯jï¼‰ï¼Œäº¤å‰ç†µå°±ç®€åŒ–ä¸ºäº†æˆ‘ä»¬ç†Ÿæ‚‰çš„è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±ã€‚
ä¿¡æ¯è®ºä¸­ä¸€ä¸ªæ›´ä¸ºæ ¸å¿ƒçš„æ¦‚å¿µæ˜¯KLæ•£åº¦ï¼ˆKullback-Leibler Divergenceï¼‰ï¼Œä¹Ÿç§°ä¸ºç›¸å¯¹ç†µï¼Œå®ƒç›´æ¥åº¦é‡äº†ä»ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒPåˆ°å¦ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒQçš„å·®å¼‚ ã€‚KLæ•£åº¦ä¸äº¤å‰ç†µä»¥åŠçœŸå®æ•°æ®åˆ†å¸ƒPçš„é¦™å†œç†µï¼ˆShannon Entropyï¼‰ä¹‹é—´å­˜åœ¨ä¸€ä¸ªåŸºæœ¬å…³ç³» ï¼š
$H(P,Q)=H(P)+D_{KL}â€‹(Pâˆ£âˆ£Q)$

é¦™å†œç†µè¡¡é‡äº†çœŸå®æ•°æ®åˆ†å¸ƒPè‡ªèº«çš„ä¸ç¡®å®šæ€§ã€‚ç”±äºåœ¨SFTçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®­ç»ƒæ•°æ®é›†æ˜¯å›ºå®šçš„ï¼Œå› æ­¤çœŸå®æ•°æ®åˆ†å¸ƒPåŠå…¶ç†µ$H(P)$æ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚è¿™æ„å‘³ç€ï¼Œæœ€å°åŒ–äº¤å‰ç†µæŸå¤±$H(P, Q)$åœ¨æ•°å­¦ä¸Šå®Œå…¨ç­‰ä»·äºæœ€å°åŒ–KLæ•£åº¦$D_{KL}(P || Q)$ã€‚å› æ­¤ï¼ŒSFTçš„å…¨éƒ¨ä¼˜åŒ–è¿‡ç¨‹å¯ä»¥è¢«ç²¾ç¡®åœ°ç†è§£ä¸ºï¼šè°ƒæ•´æ¨¡å‹å‚æ•°$\theta$ä»¥æ”¹å˜å…¶é¢„æµ‹åˆ†å¸ƒ$Q$ï¼Œä½¿å…¶ä¸çœŸå®æ•°æ®åˆ†å¸ƒPçš„KLæ•£åº¦å°½å¯èƒ½å°ï¼Œæœ€ç»ˆç›®æ ‡æ˜¯è®©Qæˆä¸ºPçš„å®Œç¾å¤åˆ»ã€‚

#### ä¿®æ­£DFTæŸå¤±ï¼šä»ç†µæœ€å°åŒ–åˆ°ç¨³å®šåŒ–ä¿¡æ¯è·å–

DFTå¯¹å•ä¸ªè¯å…ƒçš„æŸå¤±é¡¹å½¢å¼ä¸º$-p \log p$ï¼Œè¿™ä¸é¦™å†œç†µå…¬å¼$H(Q)=âˆ’âˆ‘_iâ€‹p_iâ€‹logp_iâ€‹$ä¸­çš„å•ä¸ªé¡¹å®Œå…¨ä¸€è‡´ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬éœ€è¦å¯¹è¿™ä¸€è§‚å¯Ÿçš„**ç›®æ ‡**å’Œ**æœºåˆ¶**è¿›è¡Œæ›´ç²¾ç¡®çš„ç•Œå®šã€‚

é¦–å…ˆï¼ŒDFTçš„ä¼˜åŒ–ç›®æ ‡**ä¸æ˜¯**æœ€å°åŒ–æ¨¡å‹é¢„æµ‹åˆ†å¸ƒQçš„æ€»ç†µH(Q)ã€‚å¦‚æœç›´æ¥ä»¥æœ€å°åŒ–$H(Q)$ä¸ºç›®æ ‡ï¼Œæ¨¡å‹ä¼šè¢«æ¿€åŠ±åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½åšå‡ºæåº¦è‡ªä¿¡çš„é¢„æµ‹ï¼ˆå³è¾“å‡ºä¸€ä¸ªç†µæä½çš„ã€é«˜åº¦é›†ä¸­çš„æ¦‚ç‡åˆ†å¸ƒï¼‰ï¼Œè€Œå®Œå…¨å¿½ç•¥äº†åœ°é¢çœŸå®æ ‡ç­¾ã€‚è¿™æ˜¾ç„¶ä¼šå¯¼è‡´æ¨¡å‹ä¸ç°å®è„±èŠ‚ã€‚

DFTçš„çœŸæ­£ä½œç”¨ï¼Œæ˜¯åˆ©ç”¨è¿™ä¸ªç†µå½¢å¼çš„é¡¹$-p_t \log p_t$ï¼ˆå…¶ä¸­ptâ€‹æ˜¯æ­£ç¡®è¯å…ƒçš„æ¦‚ç‡ï¼‰ä½œä¸ºå¯¹æ ‡å‡†äº¤å‰ç†µæŸå¤±$-\log p_t$çš„**åŠ æƒå› å­**ã€‚è¿™ç§åŠ æƒæœºåˆ¶çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯**ç¨³å®šå­¦ä¹ ä¿¡å·**ã€‚ä»ä¿¡æ¯è®ºçš„è§’åº¦ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·ç†è§£ï¼šKLæ•£åº¦$D_{KL}(P || Q)$å¯ä»¥è¢«è§£é‡Šä¸ºâ€œæ„å¤–ç¨‹åº¦â€ï¼ˆSurprisalï¼‰çš„æœŸæœ›å€¼ ã€‚SFTé€šè¿‡æœ€å°åŒ–KLæ•£åº¦ï¼Œè¡¨ç°å¾—åƒä¸€ä¸ªâ€œç„¦è™‘çš„â€å­¦ä¹ è€…ï¼Œå®ƒå¯¹ä»»ä½•ä¸è‡ªå·±é¢„æœŸä¸ç¬¦çš„ã€æ„Ÿåˆ°â€œæ„å¤–â€çš„æ•°æ®ç‚¹éƒ½ååº”è¿‡åº¦ã€‚å…¶`1/p`çš„éšæ€§å¥–åŠ±ç»“æ„æ­£æ˜¯è¿™ç§ç„¦è™‘çš„ä½“ç°ï¼šè¶Šæ˜¯æ„å¤–ï¼Œååº”è¶Šæ˜¯å‰§çƒˆã€‚

ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDFTé€šè¿‡ä¹˜ä»¥æ¦‚ç‡ptâ€‹æ¥å¯¹æŸå¤±è¿›è¡ŒåŠ æƒï¼Œè¡¨ç°å¾—åƒä¸€ä¸ªâ€œè‡ªä¿¡çš„â€å­¦ä¹ è€…ã€‚å®ƒæ‰¿è®¤æ•°æ®ä¸­å­˜åœ¨æ„å¤–ä¹‹å¤„ï¼Œä½†å®ƒä¸å…è®¸è¿™äº›æ„å¤–æ¥ä¸»å¯¼å’Œé¢ è¦†æ•´ä¸ªå­¦ä¹ è¿‡ç¨‹ã€‚å®ƒæ›´ç›¸ä¿¡è‡ªå·±å·²æœ‰çš„ä¸–ç•Œæ¨¡å‹ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œå¹³æ»‘ã€æ¸è¿›çš„æ›´æ–°ï¼Œå‡è®¾æ–°çš„æ•°æ®æœ€ç»ˆèƒ½å¤Ÿè¢«æ•´åˆè¿›ä¸€ä¸ªè¿è´¯çš„çŸ¥è¯†ä½“ç³»ä¸­ã€‚

æˆ‘ä»¬å¯ä»¥å°†æ¢¯åº¦çš„å¹…åº¦è§†ä¸ºæ¨¡å‹ä»ä¸€ä¸ªæ•°æ®ç‚¹å¸æ”¶ä¿¡æ¯çš„é€Ÿç‡ã€‚SFTçš„ä¿¡æ¯å¸æ”¶é€Ÿç‡æ˜¯æä¸ç¨³å®šçš„ã€å°–å³°çŠ¶çš„ï¼Œå®ƒä¼šä»â€œæ„å¤–â€çš„è¯å…ƒä¸­å¸æ”¶å·¨é‡ä¿¡æ¯ï¼Œè€Œä»â€œç¬¦åˆé¢„æœŸâ€çš„è¯å…ƒä¸­å¸æ”¶å°‘é‡ä¿¡æ¯ã€‚DFTåˆ™å¹³æ»‘äº†è¿™ä¸ªè¿‡ç¨‹ã€‚é€šè¿‡å°†æŸå¤±ä¹˜ä»¥ptâ€‹ï¼Œå®ƒç¡®ä¿äº†æ¨¡å‹ä»ä»»ä½•ä¸€ä¸ªæ­£ç¡®çš„è¯å…ƒä¸­å¸æ”¶çš„ä¿¡æ¯é‡ï¼Œä¸æ¨¡å‹å¯¹è¯¥è¯å…ƒå·²æœ‰çš„â€œä¿¡å¿µâ€å¼ºåº¦æˆæ­£æ¯”ã€‚è¿™é¿å…äº†æ¨¡å‹è¢«â€œå¼ºè¡ŒçŒè¾“â€å®ƒå°šæœªå‡†å¤‡å¥½å¤„ç†çš„ä¿¡æ¯ï¼Œä»è€Œå®ç°äº†æ›´å¥½çš„ä¿¡æ¯â€œæ¶ˆåŒ–â€å’ŒçŸ¥è¯†å†…åŒ–ã€‚

#### å¾®è°ƒæŠ‰æ‹©

- SFT
  - **åŸºç¡€æ¨¡å‹èƒ½åŠ›è¾ƒå¼±æˆ–ç¼ºä¹é¢†åŸŸçŸ¥è¯†æ—¶**ï¼šå½“åŸºç¡€æ¨¡å‹å¯¹ç›®æ ‡é¢†åŸŸå‡ ä¹æ²¡æœ‰å…ˆéªŒçŸ¥è¯†æ—¶ï¼ŒDFTçš„â€œå¼•å¯¼â€èƒ½åŠ›æ— ä»å‘æŒ¥ã€‚æ­¤æ—¶ï¼ŒSFTçš„ç›´æ¥æ¨¡ä»¿è™½ç„¶æ³›åŒ–æ€§å·®ï¼Œä½†å¯èƒ½æ˜¯è®©æ¨¡å‹å¿«é€Ÿå­¦ä¹ åŸºæœ¬æ ¼å¼å’Œæœ¯è¯­çš„å”¯ä¸€é€”å¾„ã€‚
  - **ä»»åŠ¡ç®€å•ï¼Œä¾§é‡äºé£æ ¼æ¨¡ä»¿æˆ–æ ¼å¼éµå¾ªæ—¶**ï¼šå¦‚æœä»»åŠ¡çš„æ ¸å¿ƒæ˜¯å­¦ä¹ ä¸€ç§ç‰¹å®šçš„è¾“å‡ºé£æ ¼ã€JSONæ ¼å¼æˆ–ç®€å•çš„æ–‡æœ¬è½¬æ¢ï¼Œè€Œéå¤æ‚çš„é€»è¾‘æ¨ç†ï¼ŒSFTçš„è®°å¿†èƒ½åŠ›é€šå¸¸å·²ç»è¶³å¤Ÿï¼Œä¸”å®ç°æœ€ä¸ºç®€å•ã€‚
  - **å½“è®¡ç®—å’Œå®ç°çš„ç®€æ´æ€§æ˜¯é¦–è¦è€ƒé‡æ—¶**ï¼šå°½ç®¡DFTçš„æ”¹åŠ¨æå°ï¼Œä½†åœ¨æŸäº›æç«¯è¿½æ±‚ç®€æ´çš„æµç¨‹ä¸­ï¼Œæ ‡å‡†SFTä»æ˜¯æœ€åŸºç¡€çš„é€‰æ‹©ã€‚
- DFT
  - **åŸºç¡€æ¨¡å‹å¼ºå¤§ä¸”å…·å¤‡ç›¸å…³é¢†åŸŸæ½œåœ¨èƒ½åŠ›æ—¶**ï¼šè¿™æ˜¯åº”ç”¨DFTçš„æœ€ç†æƒ³åœºæ™¯ã€‚é€‰æ‹©ä¸€ä¸ªåœ¨ç›®æ ‡é¢†åŸŸï¼ˆå¦‚æ•°å­¦ã€ä»£ç ï¼‰ç»è¿‡é¢„è®­ç»ƒæˆ–å·²çŸ¥è¡¨ç°å‡ºè‰²çš„åŸºç¡€æ¨¡å‹ï¼Œç„¶åä½¿ç”¨DFTæ¥â€œè§£é”â€å’Œâ€œå¼•å¯¼â€å…¶æ½œåŠ›ï¼Œèƒ½å¤Ÿè·å¾—æœ€ä½³æ•ˆæœ ã€‚
  - **ä»»åŠ¡å¤æ‚ï¼Œè¦æ±‚å¤šæ­¥æ¨ç†å’Œå¼ºæ³›åŒ–èƒ½åŠ›æ—¶**ï¼šå¯¹äºæ•°å­¦é¢˜è§£ç­”ã€å¤æ‚æŒ‡ä»¤éµå¾ªã€ä»£ç ç”Ÿæˆç­‰ä»»åŠ¡ï¼Œæ³›åŒ–èƒ½åŠ›è‡³å…³é‡è¦ã€‚å®éªŒæ˜ç¡®è¡¨æ˜ï¼Œåœ¨è¿™äº›ä»»åŠ¡ä¸ŠDFTè¿œèƒœäºSFTã€‚
  - **å¯»æ±‚ä»¥SFTæˆæœ¬å®ç°ç±»RLæ³›åŒ–æ•ˆæœæ—¶**ï¼šDFTæä¾›äº†ä¸€æ¡æå…·å¸å¼•åŠ›çš„ä¸­é—´è·¯çº¿ã€‚å®ƒé¿å…äº†ä¼ ç»ŸRLHFï¼ˆå¦‚PPOï¼‰æˆ–DPOæ‰€éœ€çš„å¤æ‚æµç¨‹ï¼ˆå¦‚å¥–åŠ±æ¨¡å‹è®­ç»ƒã€åœ¨çº¿é‡‡æ ·æˆ–åå¥½æ•°æ®æ”¶é›†ï¼‰ï¼Œå´èƒ½åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå¼¥è¡¥SFTä¸RLä¹‹é—´çš„æ³›åŒ–å·®è·ï¼Œæå¤§åœ°æé«˜äº†å¯¹é½è®­ç»ƒçš„æ•ˆç‡å’Œå¯åŠæ€§ã€‚

---

## ğŸ”— æ¨å¯¼

### é—®é¢˜è®¾å®šä¸ç¬¦å·

- è®­ç»ƒæ•°æ®é›†ï¼š$\mathcal{D} = \{(x, y^\star)\}$ï¼Œå…¶ä¸­ $x$ æ˜¯è¾“å…¥ï¼ˆpromptï¼‰ï¼Œ
  $y^\star = (y^\star_1, \dots, y^\star_T)$ æ˜¯ä¸“å®¶ç»™å‡ºçš„å®Œæ•´åºåˆ—ï¼ˆå›ºå®šç›®æ ‡åºåˆ—ï¼‰ã€‚
- å‚æ•°åŒ–ç­–ç•¥ï¼ˆè¯­è¨€æ¨¡å‹ï¼‰ï¼š$\pi_\theta(y\mid x)$ã€‚é“¾å¼åˆ†è§£ä¸ºï¼š
  $$
  \pi_\theta(y\mid x) = \prod_{t=1}^T \pi_\theta(y_t \mid y_{<t}, x).
  $$
- è®°å·ï¼š$\log\pi_\theta(y\mid x)=\sum_{t=1}^T \log\pi_\theta(y_t\mid y_{<t},x)$ã€‚

### SFTç›®æ ‡ä¸ç›´æ¥æ¢¯åº¦

SFT çš„ç›®æ ‡ï¼ˆé€åºåˆ—äº¤å‰ç†µï¼‰å®šä¹‰ä¸ºï¼š

$$
L_{\mathrm{SFT}}(\theta) = \mathbb{E}_{(x,y^\star)\sim\mathcal{D}}\big[-\log\pi_\theta(y^\star\mid x)\big].
$$

å¯¹å‚æ•° $\theta$ çš„æ¢¯åº¦ï¼ˆæ˜¾å¼å†™å‡ºæœŸæœ›ï¼‰ä¸ºï¼š

$$
\nabla_\theta L_{\mathrm{SFT}}(\theta) = -\,\mathbb{E}_{(x,y^\star)\sim\mathcal{D}}\big[\nabla_\theta\log\pi_\theta(y^\star\mid x)\big].
$$

è¿™æ˜¯æœ€å¸¸è§çš„äº¤å‰ç†µè®­ç»ƒï¼ˆteacher-forcingï¼‰ã€‚

### æŠŠ SFT æ”¹å†™ä¸º policy-gradient çš„å½¢å¼

#### é‡è¦æŠ½æ ·ï¼ˆImportance Samplingï¼‰

##### ç›´è§‚ç†è§£

å½“æˆ‘ä»¬æƒ³ä¼°è®¡æŸä¸ªåˆ†å¸ƒ $p$ ä¸‹çš„æœŸæœ› $\mathbb{E}_{y\sim p}[f(y)]$ï¼Œä½†ç›´æ¥ä» $p$ é‡‡æ ·å›°éš¾æˆ–ä¸æ–¹ä¾¿æ—¶ï¼Œå¯ä»¥æ”¹ç”¨å¦ä¸€ä¸ªæ›´å®¹æ˜“é‡‡æ ·çš„åˆ†å¸ƒ $q$ã€‚ä» $q$ é‡‡æ ·åï¼Œç”¨æƒé‡æŠŠæ ·æœ¬â€œæ”¹å›å»â€ï¼Œè¿™å°±æ˜¯**é‡è¦æŠ½æ ·**çš„æ€æƒ³ï¼šç”¨ $q$-æ ·æœ¬åŠ æƒå¾—åˆ° $p$ ä¸‹çš„æœŸæœ›ä¼°è®¡ã€‚

ç›´è§‚ç±»æ¯”ï¼šä½ æƒ³ä¼°è®¡é‡å¤–é±¼ç¾¤çš„å¹³å‡é‡é‡ï¼ˆçœŸæ­£çš„åˆ†å¸ƒ $p$ï¼‰ï¼Œä½†ä½ æ›´å®¹æ˜“åœ¨å…»æ®–åœºé‡‡æ ·ï¼ˆåˆ†å¸ƒ $q$ï¼‰ï¼Œäºæ˜¯ç”¨å…»æ®–åœºæ ·æœ¬å¹¶æŒ‰æ¯”ä¾‹æƒé‡æ¥æ¢å¤å¯¹é‡ç”Ÿåˆ†å¸ƒçš„ä¼°è®¡ã€‚

ç›®æ ‡ï¼šè¯æ˜å¯¹ä»»æ„å¯ç§¯å‡½æ•° $f$ï¼Œ

$$
\mathbb{E}_{y\sim p}[f(y)] \;=\; \mathbb{E}_{y\sim q}\!\left[\frac{p(y)}{q(y)}\, f(y)\right],
$$

å‰ææ˜¯ï¼šå¯¹æ‰€æœ‰ $y$ è‹¥ $p(y)>0$ åˆ™ $q(y)>0$ï¼ˆé¿å…é™¤é›¶ï¼‰ï¼Œå¹¶ä¸”æ¯”å€¼å¯ç§¯ã€‚

**ç¦»æ•£æƒ…å½¢è¯æ˜ï¼ˆç›´è§‚ï¼‰**ï¼š

$$
\begin{align*}
\mathbb{E}_{y\sim p}[f(y)] &= \sum_y p(y) f(y) \\
&= \sum_y q(y)\,\frac{p(y)}{q(y)}\,f(y) \\
&= \mathbb{E}_{y\sim q}\!\left[\frac{p(y)}{q(y)} f(y)\right].
\end{align*}
$$

è¿ç»­æƒ…å½¢åŒç†ï¼Œç”¨ç§¯åˆ†æ›¿æ¢æ±‚å’Œã€‚ç”±æ­¤å¾—åˆ°**æ— åä¼°è®¡é‡**ï¼šè‹¥ä» $q$ æŠ½å– $N$ ä¸ªç‹¬ç«‹æ ·æœ¬ $y^{(i)}$ï¼Œåˆ™

$$
\hat\mu = \frac{1}{N}\sum_{i=1}^N \frac{p(y^{(i)})}{q(y^{(i)})}\, f(y^{(i)})
$$

æ»¡è¶³ $\mathbb{E}[\hat\mu] = \mathbb{E}_{p}[f]$ã€‚

å‡è®¾æ ·æœ¬ç©ºé—´ $\{a,b\}$ï¼š

- çœŸå®åˆ†å¸ƒ $p$: $p(a)=0.8,\ p(b)=0.2$ï¼›
- é‡è¦åˆ†å¸ƒ $q$: $q(a)=0.5,\ q(b)=0.5$ï¼›
- å‡½æ•¸å€¼ $f(a)=2,\ f(b)=4$ã€‚

ç›´æ¥è®¡ç®—ï¼š

$$
\mathbb{E}_p[f] = 0.8\cdot 2 + 0.2\cdot 4 = 1.6 + 0.8 = 2.4.
$$

ç”¨ importance samplingï¼ˆä» $q$ æŠ½æ ·ï¼‰ï¼š

$$
\begin{align*}
\mathbb{E}_q\!\left[\frac{p}{q} f\right]
&= q(a)\frac{p(a)}{q(a)} f(a) + q(b)\frac{p(b)}{q(b)} f(b) \\
&= 0.5\cdot\frac{0.8}{0.5}\cdot 2 + 0.5\cdot\frac{0.2}{0.5}\cdot 4 = 1.6 + 0.8 = 2.4.
\end{align*}
$$

#### SFT â†’ policy-gradient æ¨å¯¼ä¸­çš„è§’è‰²

ç›®æ ‡ï¼šå°†ä¸Šå¼è¡¨ç¤ºæˆåœ¨æ¨¡å‹é‡‡æ ·åˆ†å¸ƒ $y\sim\pi_\theta(\cdot\mid x)$ ä¸‹çš„æœŸæœ›ï¼Œä»è€Œæ˜¾å¼å‡ºç°é‡è¦æ€§æƒé‡å¹¶ä¸ policy-gradient å¯¹æ¯”ã€‚

å¯¹ä»»æ„å¯æµ‹å‡½æ•° $f(x,y)$ï¼Œé‡è¦æŠ½æ ·æ’ç­‰å¼ä¸ºï¼š

$$
\mathbb{E}_{(x,y)\sim\mathcal{D}}[f(x,y)]
= \mathbb{E}_{x\sim D_x}\Big[\sum_y p_{\mathcal{D}}(y\mid x)\,f(x,y)\Big]
= \mathbb{E}_{x\sim D_x,\ y\sim\pi_\theta(\cdot\mid x)}\Big[\frac{p_{\mathcal{D}}(y\mid x)}{\pi_\theta(y\mid x)}\,f(x,y)\Big].
$$

åœ¨è®­ç»ƒæ•°æ®ä¸­é€šå¸¸ $p_{\mathcal{D}}(y\mid x)=\mathbf{1}[y=y^\star]$ï¼ˆæŒ‡ç¤ºå‡½æ•°ï¼‰ã€‚è®¾

$$
w(y\mid x)=\frac{1}{\pi_\theta(y\mid x)},\qquad r(x,y)=\mathbf{1}[y=y^\star].
$$

æŠŠ $f(x,y)=-\nabla_\theta\log\pi_\theta(y\mid x)$ ä»£å…¥ï¼Œå¾—åˆ°ï¼š

$$
\nabla_\theta L_{\mathrm{SFT}}(\theta)
= -\,\mathbb{E}_{x\sim D_x,\ y\sim\pi_\theta}\Big[\frac{\mathbf{1}[y=y^\star]}{\pi_\theta(y\mid x)}\ \nabla_\theta\log\pi_\theta(y\mid x)\Big].
$$

ç´§å‡‘å†™æ³•ä¸ºï¼š

$$
\boxed{\displaystyle \nabla_\theta L_{\mathrm{SFT}}(\theta)
= -\,\mathbb{E}_{x,y\sim\pi_\theta}\big[ w(y\mid x)\,r(x,y)\,\nabla_\theta\log\pi_\theta(y\mid x)\big],}
$$

å…¶ä¸­ $w=1/\pi$ã€‚è¿™å°±æ˜¯æŠŠ SFT çœ‹æˆ policy-gradient çš„å…³é”®æ’ç­‰å¼ï¼Œä½†æ³¨æ„å‡ºç°äº†é‡è¦æ€§æƒé‡ $1/\pi$ï¼ˆå¯èƒ½å¯¼è‡´æ•°å€¼é—®é¢˜ï¼‰ã€‚

### ä¸ºä»€ä¹ˆ $1/\pi$ ä¼šå¯¼è‡´æ–¹å·® / æ•°å€¼é—®é¢˜

#### å®šä¹‰ï¼šäºŒé˜¶çŸ©

å¯¹äº$X$ï¼Œå…¶ äºŒé˜¶çŸ© é€šå¸¸æŒ‡ $\mathbb{E}[X^2]$ï¼ˆæ ‡é‡æƒ…å½¢ï¼‰æˆ– $\mathbb{E}[\|X\|^2]$ï¼ˆå‘é‡æƒ…å½¢ï¼Œ$\|\cdot\|$ ä¸ºæ¬§å‡ é‡Œå¾—èŒƒæ•°ï¼‰ã€‚äºŒé˜¶çŸ©ä¸æ˜¯æ–¹å·®ï¼š

$$
\mathrm{Var}(X) \;=\; \mathbb{E}\big[(X-\mathbb{E}[X])^2\big] \;=\; \mathbb{E}[X^2] - (\mathbb{E}[X])^2.
$$

å› æ­¤è‹¥ $\mathbb{E}[X^2]$ å¾ˆå¤§ï¼Œå³ä½¿ $\mathbb{E}[X]$ ä¸ç®—å¤§ï¼Œæ–¹å·®ä¹Ÿå¯èƒ½å¾ˆå¤§ã€‚

ä½¿ç”¨é‡è¦æŠ½æ ·æ—¶ï¼Œå•æ ·æœ¬çš„è´¡çŒ®ä¸º$W(y) f(y)$ï¼Œå…¶ä¸­ $W=p/q$ï¼Œå•æ ·æœ¬è´¡çŒ®äºŒé˜¶çŸ© $\mathbb{E}_q[(W f)^2]$ ã€‚è‹¥ $W$ æœ‰é‡å°¾ï¼ˆæŸäº›æ ·æœ¬çš„ $W$ å¾ˆå¤§ï¼‰ï¼Œåˆ™ $\mathbb{E}_q[W^2 f^2]$ ä¼šéå¸¸å¤§ï¼Œå¯¼è‡´æ–¹å·®å·¨å¤§ã€ä¸ç©©å®šã€‚

ç›´è§‚ï¼šè¢« $q$ è¦†ç›–ä½†æ¦‚ç‡ç»©æ•ˆçš„æ ·æœ¬ï¼Œä¼šå›  $W$ å¾ˆå¤§è€Œåœ¨è¢«æ”¾å¤§ï¼Œå•ä¸ªç½•è§æ ·æœ¬å¯èƒ½ä¸»å¯¼æ•´ä¸ªè®¡ç®—ã€‚

å¯¹äºå›ºå®š $x$ï¼Œå•æ ·æœ¬ï¼ˆSFT åœ¨ policy-gradient è§†è§’ä¸‹ï¼‰æ˜¯ï¼š

$$
G(x,y) \;=\; -\,\frac{\mathbf{1}[y=y^\star]}{\pi_\theta(y\mid x)}\,\nabla_\theta\log\pi_\theta(y\mid x).
$$

è®¡ç®—äºŒé˜¶çŸ©ï¼ˆå¯¹ $y\sim\pi_\theta$ï¼‰ï¼š

$$
\begin{align*}
\mathbb{E}_{y\sim\pi}\big[\|G\|^2\big]
&= \pi_\theta(y^\star\mid x)\ \Big\|\frac{1}{\pi_\theta(y^\star\mid x)}\,\nabla_\theta\log\pi_\theta(y^\star\mid x)\Big\|^2 \\[4pt]
&= \frac{1}{\pi_\theta(y^\star\mid x)}\ \big\|\nabla_\theta\log\pi_\theta(y^\star\mid x)\big\|^2.
\end{align*}
$$

å› æ­¤å½“ $\pi_\theta(y^\star\mid x)$ å¾ˆå°æ—¶ï¼ˆä¾‹å¦‚ $0.01$ï¼‰ï¼ŒäºŒé˜¶çŸ©ä¼šè¢«æ”¾å¤§ï¼ˆæŒ‰ $1/\pi$ æ¯”ä¾‹ï¼‰ï¼Œå¯¼è‡´æ–¹å·®å·¨å¤§ã€‚

### DFT çš„æ ¸å¿ƒæƒ³æ³•ä¸æ•°å­¦è¡¨è¾¾ï¼ˆstop-gradient çš„ä½œç”¨ï¼‰

**æ•°å€¼ä¸Šçš„ä¿®æ”¹**ï¼šæŠŠæ¯ä¸ªä¸“å®¶ token çš„äº¤å‰ç†µé¡¹ä¹˜ä»¥å¯¹åº”çš„æ¨¡å‹æ¦‚ç‡ï¼ˆæ•°å€¼ä¸Šï¼‰ï¼Œä½†å¯¹è¯¥æ¦‚ç‡ä½¿ç”¨ stop-gradientï¼ˆä¸è®©è¯¥æ¦‚ç‡å‚ä¸åå‘ä¼ æ’­ï¼‰ã€‚

åºåˆ—çº§ç›´è§‚å†™æ³•ï¼ˆå¸¦ stop-gradientï¼‰ä¸ºï¼š

$$
\nabla_\theta L_{\mathrm{DFT}}(\theta)
= -\,\mathbb{E}_{(x,y^\star)\sim\mathcal{D}}\big[\mathrm{sg}\big(\pi_\theta(y^\star\mid x)\big)\,\nabla_\theta\log\pi_\theta(y^\star\mid x)\big],
$$

å…¶ä¸­ $\mathrm{sg}(\cdot)$ è¡¨ç¤º stop-gradientï¼ˆå‰å‘è®¡ç®—ä½¿ç”¨æ•°å€¼ï¼Œåå‘ä¸ä¼ æ’­ï¼‰ã€‚

ç”¨é‡è¦æŠ½æ ·æ”¹å†™ä¸ºåœ¨ $y\sim\pi_\theta$ ä¸‹çš„æœŸæœ›ï¼š

$$
\nabla_\theta L_{\mathrm{DFT}}(\theta)
= -\,\mathbb{E}_{x,y\sim\pi_\theta}\Big[\frac{\mathbf{1}[y=y^\star]}{\pi_\theta(y\mid x)}\ \mathrm{sg}\big(\pi_\theta(y^\star\mid x)\big)\ \nabla_\theta\log\pi_\theta(y\mid x)\Big].
$$

åœ¨ $y=y^\star$ çš„æƒ…å½¢ï¼Œæ•°å€¼ä¸Šæœ‰ï¼š

$$
\frac{\mathrm{sg}\big(\pi_\theta(y^\star\mid x)\big)}{\pi_\theta(y^\star\mid x)}
= \frac{\pi_\theta(y^\star\mid x)}{\pi_\theta(y^\star\mid x)} = 1.
$$

ï¼ˆè¿™é‡Œçš„å…³é”®æ˜¯ï¼š`sg` ä¸æ”¹å˜å‰å‘æ•°å€¼ï¼Œåªé˜»æ–­æ¢¯åº¦ã€‚ï¼‰å› æ­¤æ•°å€¼ä¸Šæ•´é¡¹å˜ä¸ºï¼š

$$
-\,\mathbb{E}_{x,y\sim\pi_\theta}\big[\mathbf{1}[y=y^\star]\,\nabla_\theta\log\pi_\theta(y\mid x)\big],
$$

ä¹Ÿå°±æ˜¯

$$
\boxed{\nabla_\theta L_{\mathrm{DFT}}(\theta)
= -\,\mathbb{E}_{x\sim D_x}\big[\pi_\theta(y^\star\mid x)\,\nabla_\theta\log\pi_\theta(y^\star\mid x)\big].}
$$

$$
\mathbb{E}[\|G_{\text{DFT}}\|^2] = \pi_\theta(y^\star\mid x)\ \|\nabla_\theta\log\pi_\theta(y^\star\mid x)\|^2,
$$

è¿™ä¸ªè¡¨è¾¾åœ¨æ•°å€¼ä¸Šä¸å†åŒ…å« $1/\pi$ï¼Œä»è€Œæ˜¾è‘—é™ä½äºŒé˜¶çŸ©æ–¹å·®ï¼›åœ¨ RL æœ¯è¯­ä¸‹ç›¸å½“äºæŠŠ reward çŸ«æ­£ä¸ºæ’ç­‰äº $1$ çš„ï¼ˆæ›´ç¨³å®šçš„ï¼‰ç­–ç•¥æ¢¯åº¦ä¼°è®¡ã€‚

### Token-level ç­‰ä»·å®ç°

ä»¤ logits ä¸º $z_k$ï¼Œsoftmax å®šä¹‰ä¸º $\pi(k) = \frac{e^{z_k}}{\sum_j e^{z_j}}$ï¼Œåˆ™

$$
\frac{\partial \log\pi(i)}{\partial z_k} = \mathbf{1}[k=i] - \pi(k).
$$

å› æ­¤å¯¹å‚æ•° $\theta$ æœ‰

$$
\nabla_\theta \log\pi(i) = \sum_k (\mathbf{1}[k=i]-\pi(k))\,\nabla_\theta z_k
= \nabla_\theta z_i - \sum_k \pi(k)\,\nabla_\theta z_k.
$$

åœ¨ DFT çš„ token-level æ¢¯åº¦ä¸­ï¼š

$$
\nabla_\theta\big(-\mathrm{sg}(\pi)\log\pi\big) = -\mathrm{sg}(\pi)\,\nabla_\theta\log\pi,
$$

å› ä¸º $\mathrm{sg}(\pi)$ åœ¨åå‘ä¼ æ’­æ—¶è¢«è§†ä¸ºå¸¸æ•°ï¼ˆä¸ä¾èµ–äº $\theta$ï¼‰ã€‚

ä¸ºäº†æ•°å€¼ç¨³å®šä¸å®ç°æ–¹ä¾¿ï¼Œé€šå¸¸å°† sequence-level çš„ä¹˜å­æ‹†æˆé€ token çš„ä¹˜å­ã€‚åœ¨è®­ç»ƒæ—¶ä½¿ç”¨ä¸‹é¢çš„ lossï¼š

$$
L_{\mathrm{DFT}}(\theta)
= \mathbb{E}_{(x,y^\star)\sim\mathcal{D}}\Big[ -\sum_{t=1}^T \mathrm{sg}\big(\pi_\theta(y^\star_t\mid y^\star_{<t},x)\big)\ \log\pi_\theta(y^\star_t\mid y^\star_{<t},x)\Big].
$$

é€ token å±•å¼€åï¼Œæ¯ä¸ª token çš„ $1/\pi$ éƒ½ä¼šè¢«å…¶å¯¹åº”çš„ $\pi$ï¼ˆæ•°å€¼ï¼‰æŠµæ¶ˆï¼Œä»è€Œä½¿å¾— token çº§åˆ«çš„ä¼°è®¡é‡æ²¡æœ‰ $1/\pi$ çš„æ”¾å¤§å› å­ã€‚

**å®ç°ç»†èŠ‚ï¼ˆPyTorch é£æ ¼ä¼ªä»£ç ï¼‰**ï¼š

```python
import torch
import torch.nn.functional as F

# logits: (batch, seq_len, vocab)
# target: (batch, seq_len)  (ç›®æ ‡åºåˆ—ï¼Œpad å·²å¤„ç†)
# loss_mask: (batch, seq_len)  (1: æœ‰æ•ˆ token, 0: padding)

logits = model(input_ids, attention_mask=...)  # (B, T, V)
log_probs = F.log_softmax(logits, dim=-1)     # (B, T, V)

# target_logp: (B, T)
target_logp = log_probs.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)

# token-level model-probabilities (æ•°å€¼ä¹˜å­)ï¼Œå¹¶ stop-gradient
token_prob = target_logp.exp().detach()      # (B, T)

# dft per-token loss, æ³¨æ„ detach åªå¯¹ token_prob ç”Ÿæ•ˆ
per_token_loss = - token_prob * target_logp   # (B, T)

# mask padding tokens
per_token_loss = per_token_loss * loss_mask

# final loss: mean over non-pad tokens
loss = per_token_loss.sum() / loss_mask.sum()

loss.backward()
# optimizer.step(), etc.
```

å…³é”®ç‚¹ï¼šä½¿ç”¨ `token_prob = target_logp.exp().detach()` ç¡®ä¿ `token_prob` åœ¨åå‘ä¼ æ’­æ—¶æ²¡æœ‰æ¢¯åº¦ï¼Œè¿™æ ·æ¢¯åº¦åªæ¥è‡ª `target_logp`ï¼ˆå³ $\log\pi$ï¼‰ï¼Œä¹˜å­åªæ˜¯æ•°å€¼ç¼©æ”¾å› å­ã€‚
